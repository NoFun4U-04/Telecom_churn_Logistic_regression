


import pandas as pd
import numpy as np
#thư viện matplotlib, seaborn để vẽ biểu đồ trực quan hóa dữ liệu
import matplotlib.pyplot as plt
import seaborn as sns
#thư viện sklearn để biến đổi và chuẩn hóa dữ liệu
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
#thư viện chia dữ liệu thành tập huấn luyện và tập kiểm tra
from sklearn.model_selection import train_test_split
#Thư viện khia báo mô hình Logistic Regresstion
from sklearn.linear_model import LogisticRegression
#Các chỉ số đánh giá accuracy, precision, recall, f1
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
# giải quyết mất cân bàng dữ liệu 
from imblearn.over_sampling import SMOTE


#Nhập dữ liệu vào df
df = pd.read_csv('telco_churn.csv')
df








#xem xét 5 dòng đầu của dữ liệu
df.head()





df_2 = df.iloc[:,2:]
df_2


df_2.info()


#gender column
gender = df_2['gender'].value_counts()
gender.plot(kind='bar', color='skyblue', edgecolor='black')
plt.title('Số lượng các giá trị')
plt.ylabel('Số lượng')
print(gender)
plt.show()




# Tương tự với các thuộc tính còn lại
columns_to_plot = [
    'Partner',
    'Dependents',
    'SeniorCitizen',
    'PhoneService',
    'MultipleLines',
    'InternetService',
    'OnlineSecurity',
    'OnlineBackup',
    'DeviceProtection',
    'TechSupport',
    'StreamingTV',
    'StreamingMovies',
    'Contract',
    'PaperlessBilling',
    'PaymentMethod'
]
# Lặp qua từng cột và vẽ biểu đồ
for column in columns_to_plot:
    plt.figure(figsize=(3, 2)) 
    df_2[column].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')
    plt.title(f'Số lượng các giá trị trong cột {column}')
    plt.ylabel('Số lượng')
    plt.xlabel(column)
    print( df_2[column].value_counts())
    plt.show() 



# biểu đồ dữ liệu thì ta cần thay đổi các giá trị dữ liệu sao cho phù hợp ở cột  [Partner], [Dependents], [SeniorCitizen] ,
#[PhoneService], [MultipleLines], [OnlineSecurity], [OnlineBackup], [DeviceProtection], [TechSupport], [StreamingTV]. [StreamingMovies]
#[PaperlessBilling]


#replace partner -- Khách hàng có đối tác hay không
df_2['Partner'] = df_2['Partner'].replace({'TRUE': 'Yes', 'FALSE': 'No'})
#replace Dependents -- khách hàng có người thân hay không
df_2['Dependents'] = df_2['Dependents'].replace({'TRUE': 'Yes', 'FALSE': 'No'})
#replace SeniorCitizen -- Khách hàng có phải là người cao tuổi hay không 
df_2['SeniorCitizen'] = df_2['SeniorCitizen'].replace({'TRUE': '1', 'FALSE': '0'})
#replace PhoneService  -- Khách hàng có sử dụng dịch vụ điện thoại hay không
df_2['PhoneService'] = df_2['PhoneService'].replace({'TRUE': 'Yes', 'FALSE': 'No'})
#replace MultipleLines -- Khách hàng có nhiều sử dụng nhiều đường dây hay không
df_2['MultipleLines'] = df_2['MultipleLines'].replace({'TRUE': 'Yes', 'FALSE': 'No', 'No phone service': 'No'})
#replace OnlineSecurity -- Khách hàng có bảo mật trực tuyến hay không
df_2['OnlineSecurity'] = df_2['OnlineSecurity'].replace({'TRUE': 'Yes', 'FALSE': 'No', 'No internet service': 'No'})
#replace OnlineBackup -- Khách hàng có sao lưu trực tuyến hay không 
df_2['OnlineBackup'] = df_2['OnlineBackup'].replace({'TRUE': 'Yes', 'FALSE': 'No', 'No internet service': 'No'})
#replace DeviceProtection -- Kháhc hàng có bảo vệ các thiết bị hay không
df_2['DeviceProtection'] = df_2['DeviceProtection'].replace({'TRUE': 'Yes', 'FALSE': 'No', 'No internet service': 'No'})
#replace TechSupport -- Khách hàng có hỗ trợ kĩ thuật hay khong 
df_2['TechSupport'] = df_2['TechSupport'].replace({'TRUE': 'Yes', 'FALSE': 'No', 'No internet service': 'No'})
#replace StreamingTV -- Khách hàng có sử dụng dịch vụ phát truyền hình rực tuyến hay không 
df_2['StreamingTV'] = df_2['StreamingTV'].replace({'TRUE': 'Yes', 'FALSE': 'No', 'No internet service': 'No'})
#replace StreamingMovies -- Khách hàng có sử dụng dịch vụ phát phim trực tuyến hay không 
df_2['StreamingMovies'] = df_2['StreamingMovies'].replace({'TRUE': 'Yes', 'FALSE': 'No', 'No internet service': 'No'})
#replace PaperlessBilling -- Kháng thanh toán không cần giấy tờ 
df_2['PaperlessBilling'] = df_2['PaperlessBilling'].replace({'TRUE': 'Yes', 'FALSE': 'No'})


df_2


#Xem số lương của các giá trị của biến phụ thuộc
Churn = df_2['Churn'].value_counts()
Churn.plot(kind='bar', color = 'red')
plt.title('Số lượng các giá trị của Churn')
plt.ylabel('số lượng')
plt.show()


df_2.iloc[:,-1] = df_2.iloc[:,-1].replace({"TRUE": "Yes", "FALSE":"No"})



#xem lại toàn bộ bảng 
df_2.info()


df_2.describe()


#Handling Missing Data
df_null = df_2[df_2.isna().any(axis=1)]
df_null.isna().sum()
plt.figure(figsize=(10,5))
sns.heatmap(df_null.isna(), cmap='viridis')
plt.xlabel('Missing data')
plt.ylabel('Vị trí các phần tử bị thiếu')
plt.show()


df_null


# Danh sách các cột cần thay thế giá trị NaN
columns_to_replace = [
    'OnlineSecurity', 
    'OnlineBackup', 
    'DeviceProtection', 
    'TechSupport', 
    'StreamingTV', 
    'StreamingMovies'
]
df_2[columns_to_replace] = df_2[columns_to_replace].fillna('No')


df_2.isna().sum()


#tỉ lệ yes no của cột multipleLines
df_2['MultipleLines'].isna().sum()
#Xóa bỏ các bản ghi mà có  bị thiếu 
df_2 = df_2.dropna(subset=['MultipleLines'])
churn_null = df_2[df_2['Churn'].isna()]
df_2 = df_2.dropna(subset=['Churn'])
TotalCharges_null = df_2[df_2['TotalCharges'].isna()]
df_3 = df_2.dropna(subset=['TotalCharges'])


df_3.info()





df_3


df_3.info()


#ở đây chỉ có 3 cột tuyến tính là tenure, MonthlyCharges, TotalCharges
#Chúng ta xét xem ở đây có giá trị ngoại lai hay không
df_3['TotalCharges'] =  pd.to_numeric(df_3['TotalCharges'])



# Lọc các dòng có giá trị chuỗi trống trong cột 'TotalCharges'
index = df_3[df_3['TotalCharges'].str.strip() == '']

# In ra các dòng có giá trị chuỗi trống
print(index)



index = [4754,4670,3218]
df_3 = df_3.drop(index, axis = 0)


df_3['TotalCharges'] =  pd.to_numeric(df_3['TotalCharges'])
df_3.info()


#xem độ đo phân tán các giá trị của ác thuộc tính tuyến tính
#Chuyển các dữ liệu tuyến tính về dạng số
df_3['TotalCharges'] =  pd.to_numeric(df_3['TotalCharges'])
df_3.info()

plt.boxplot(df_3.iloc[:,4], patch_artist=True, showmeans = True)
plt.title('độ đo phân tán của tenure')
plt.show()
          
plt.boxplot(df_3['MonthlyCharges'], patch_artist=True, showmeans = True)
plt.title('độ đo phân tán của MonthlyCharges')
plt.show()

plt.boxplot(df_3['TotalCharges'], patch_artist=True, showmeans = True)
plt.title('độ đo phân tán của TotalCharges')
plt.show()


plt.hist(df_3['tenure'], bins=20)
plt.show()











#thuộc tính chưa giá trị tuyến tính
number = ['tenure', 'MonthlyCharges', 'TotalCharges']# chuẩn hóa dữ liệu bằng z-score
index_1 = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
          'TechSupport', 'StreamingTV', 'StreamingMovies', 'Churn']# thuộc tính có hai giá trị yes or no sử dụng LabelEnCoding
index_2 = ['InternetService', 'Contract', 'PaperlessBilling', 'PaymentMethod']# thuộc tính có hơn hai giá trị sử dụng OneHotEncoding


df_4=df_3
df_4 = df_4.reset_index(drop=True)
df_4



#Biến đổi các thuộc tính có hai giá trị thành 0 và 1
LE = LabelEncoder()
for col in index_1 :
 df_4[col] = LE.fit_transform(df_3[col])
df_4



onehot_encoder = OneHotEncoder(sparse_output=False)  
# Fit và transform dữ liệu
encoded_data = onehot_encoder.fit_transform(df_4[index_2])
encoded_df = pd.DataFrame(encoded_data, columns=onehot_encoder.get_feature_names_out(index_2))



df_combined = pd.concat([encoded_df, df_4], axis=1)
df_combined = df_combined.drop(columns=index_2)
df_combined


#Thuộc tính có tính tương quan cao qua ma trận tương quan
corr_matrix = df_combined.corr()
plt.figure(figsize = (12,12))
sns.heatmap(corr_matrix, annot = True, fmt ='.1f', cmap='coolwarm', cbar = True)
plt.title("Ma trân trương quan giữa các thuộc tính")
plt.savefig("corr_matrix.png", format="png") 


plt.savefig("corr_matrix_1.png", format="png") 








X_train, X_test, y_train, y_test = train_test_split(df_combined.drop('Churn', axis=1), 
                                                    df_combined['Churn'], 
                                                    test_size=0.2, 
                                                    random_state=42, 
                                                    stratify= df_combined['Churn'])



# chuẩn hóa dữ liệu bằng z-score
scaler = StandardScaler()
X_train[number] = scaler.fit_transform(X_train[number])
X_train



X_test[number] = scaler.fit_transform(X_test[number])
X_test


X_train.shape





model_LogisticRegression = LogisticRegression(
    tol=1e-4,              # Sai số cho điều kiện hội tụ
    solver='lbfgs',        # Thuật toán tối ưu: 'liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'
    max_iter=100,          # Số lần lặp tối đa cho thuật toán tối ưu
)


model_LogisticRegression.fit(X_train,y_train)





print('hệ số coef:', model_LogisticRegression.coef_)


print('hệ số chặn intercept:', model_LogisticRegression.intercept_)





y_pred = model_LogisticRegression.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc_roc = roc_auc_score(y_test, y_pred)

# Tạo DataFrame rỗng với các cột đánh giá
results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])

# Tạo DataFrame tạm thời với các kết quả
new_row = pd.DataFrame([{
    'Model': model_LogisticRegression,
    'Accuracy': accuracy,
    'Precision': precision,
    'Recall': recall,
    'F1 Score': f1,
}])

# Dùng pd.concat để thêm hàng mới vào DataFrame
results_df = pd.concat([results_df, new_row], ignore_index=True)

print(results_df)





# chia thành biến đọc lập và biến phụ thuộc
X = df_combined.drop('Churn', axis=1)
y = df_combined['Churn']
print(X.shape)
print(y.shape)
y.value_counts()


smote = SMOTE(sampling_strategy='minority')
X_resampled, y_resampled= smote.fit_resample(X, y)
y_resampled.value_counts()
print(X_resampled.shape)


X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_resampled, 
                                                    y_resampled, 
                                                    test_size=0.2, 
                                                    random_state=42, 
                                                    stratify= y_resampled)


scaler = StandardScaler()
X_train_2[number] = scaler.fit_transform(X_train_2[number])
X_train_2
X_test_2[number] = scaler.fit_transform(X_test_2[number])
X_test_2


model_LogisticRegression_2 = LogisticRegression()
model_LogisticRegression_2.fit(X_train_2, y_train_2)


print('hệ số coef:', model_LogisticRegression.coef_)
print('hệ số chặn intercept:', model_LogisticRegression.intercept_)


# Đánh giá kết quả 
y_pred_2 = model_LogisticRegression_2.predict(X_test_2)


accuracy = accuracy_score(y_test_2, y_pred_2)
precision = precision_score(y_test_2, y_pred_2)
recall = recall_score(y_test_2, y_pred_2)
f1 = f1_score(y_test_2, y_pred_2)


print('accuracy:', accuracy, 'precision:', precision, 'recall:', recall, 'f1:', f1)






class Logistic_Regression:
    #Khai báo các chỉ số
    def __init__(self, learning_rate, iter):
        self.learning_rate = learning_rate
        self.iter = iter
        self.w = None
        self.b = None
    # Hàm kích hoạt sigmoid
    def sigmoid(self,z):
        return 1/(1+np.exp(-z))
    #Hàm loss function
    def loss_function(self, y, y_pred):
        return -np.mean(y*np.log(y_pred) - (1-y)*np.log(1-y_pred))
    
    def Logistic_Regression(self, X, y):
        n_samples, n_features = X.shape
        self.w = np.zeros((n_features, 1))
        self.b = 0  
        y = y.reshape((-1, 1))
        #forward propagation
        for i in range(self.iter):
            z = np.dot(X, self.w) + self.b
            y_pred = self.sigmoid(z)
            
            #gradient descent
            w_gradient = np.dot(X.T, (y_pred - y))/n_samples
            b_gradient = np.sum(y_pred - y)/n_samples
            #cập nhật các trọng số
            self.w = self.w - self.learning_rate*w_gradient
            self.b = self.b - self.learning_rate*b_gradient
            #in ra tỉ lệ hàm mất mát 
            if i % 50 == 0:
                loss_function = self.loss_function(y, y_pred)
                print(f"Iteration {i}, Loss: {loss_function:.10f}")
    #Khớp với mô hình
    def fit(self, X, y):
        self.Logistic_Regression(X, y)
    #Dự đoán
    def predict(self, X):
        z = z = np.dot(X, self.w) + self.b
        y_pred = self.sigmoid(z)
        #tạo mảng chứa giá trị dự đoán
        y_pred_array = []
        for i in y_pred:
            if i >= 0.5: 
                y_pred_array.append(1)
            else:
                y_pred_array.append(0)
        return np.array(y_pred_array)
        
    #các thông số đánh giá
    
    def accuracy(self, X, y):
        y_pred = self.predict(X)
        return accuracy_score(y, y_pred)
        
    def precision(self, X, y):
        y_pred = self.predict(X)
        return precision_score(y, y_pred)
        
    def recall(self, X, y):
        y_pred = self.predict(X)
        return recall_score(y, y_pred)
        
    def f1(self, X, y):
        y_pred = self.predict(X)
        return f1_score(y, y_pred)


if __name__ == "__main__":
    from sklearn.datasets import make_classification


model_LogisticRegression_3 = Logistic_Regression(learning_rate=0.0001, iter=300)
X_train_3= X_train_2.to_numpy()  
y_train_3= y_train_2.to_numpy()  
model_LogisticRegression_3.fit(X_train_3, y_train_3)


X_test_3= X_test_2.to_numpy()  
y_test_3= y_test_2.to_numpy()


y_pred_3 = model_LogisticRegression_3.predict(X_test_3)


accuracy = accuracy_score(y_test_3, y_pred_3)
precision = precision_score(y_test_3, y_pred_3)
recall = recall_score(y_test_3, y_pred_3)
f1 = f1_score(y_test_3, y_pred_3)
auc_roc = roc_auc_score(y_test_3, y_pred_3)

# Tạo DataFrame rỗng với các cột đánh giá
results_df_1 = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC'])

# Tạo DataFrame tạm thời với các kết quả
new_row_1 = pd.DataFrame([{
    'Model': model_LogisticRegression,
    'Accuracy': accuracy,
    'Precision': precision,
    'Recall': recall,
    'F1 Score': f1,
    'AUC-ROC': auc_roc
}])

# Dùng pd.concat để thêm hàng mới vào DataFrame
results_df_1 = pd.concat([results_df_1, new_row_1], ignore_index=True)

print(results_df)






